import { GoogleGenAI, type Part } from '@google/genai';

export interface InputImage {
  base64: string;
  mimeType: 'image/jpeg' | 'image/png' | 'image/webp';
}

// Model configurations based on Google AI documentation research
// - Only includes models that support image generation
// - Gemini image models use generateContent with responseModalities: ['IMAGE']
// - Imagen uses a separate generateImages method
// - supportsBatch indicates if the model can be used with batch processing
export const MODELS = [
  {
    id: 'gemini-3-pro-image-preview',
    label: 'Gemini 3 Pro',
    type: 'gemini',
    supportsBatch: true,
    default: true,
  },
  {
    id: 'imagen-4.0-generate-001',
    label: 'Imagen 4',
    type: 'imagen',
    supportsBatch: false,
  },
] as const;

export type ModelId = (typeof MODELS)[number]['id'];
export type ModelType = (typeof MODELS)[number]['type'];

/**
 * Returns the default model ID for a given context.
 * @param batchOnly If true, only considers models that support batch processing.
 * @returns The ID of the model marked as default, or the first supported model.
 */
export function getDefaultModelId(batchOnly = false): string {
  const models = batchOnly ? MODELS.filter((m) => m.supportsBatch) : MODELS;
  const defaultModel = models.find((m) => 'default' in m && m.default);
  return defaultModel?.id ?? models[0]?.id ?? 'gemini-3-pro-image-preview';
}

export class ImageGenerator {
  private ai: GoogleGenAI;
  private apiKey: string;
  private systemPrompt: string;
  private model: string;
  private modelType: ModelType;

  constructor(
    apiKey: string,
    systemPrompt: string,
    model: string = 'gemini-3-pro-image-preview',
  ) {
    this.ai = new GoogleGenAI({ apiKey });
    this.apiKey = apiKey;
    this.systemPrompt = systemPrompt;
    this.model = model;

    // Determine model type
    const modelConfig = MODELS.find((m) => m.id === model);
    this.modelType = modelConfig?.type ?? 'gemini';
  }

  async generate(
    userPrompt: string,
    images?: InputImage[],
  ): Promise<string | null> {
    try {
      if (this.modelType === 'imagen') {
        return await this.generateWithImagen(userPrompt);
      } else {
        return await this.generateWithGemini(userPrompt, images);
      }
    } catch (error: any) {
      throw new Error(`Error generating image: ${error.message}`);
    }
  }

  private async generateWithGemini(
    userPrompt: string,
    images?: InputImage[],
  ): Promise<string | null> {
    // Build content parts
    const parts: Part[] = [];

    // Add the text prompt
    parts.push({ text: this.systemPrompt + userPrompt });

    // Add all images if provided
    if (images && images.length > 0) {
      for (const image of images) {
        parts.push({
          inlineData: {
            data: image.base64,
            mimeType: image.mimeType,
          },
        });
      }
    }

    const response = await this.ai.models.generateContent({
      model: this.model,
      contents: parts,
      config: {
        responseModalities: ['IMAGE'],
      },
    });

    const reason = response.candidates?.[0]?.finishReason;

    if (!response.candidates) {
      throw new Error('No candidates in response');
    }

    if (reason !== 'STOP') {
      throw new Error(reason || 'Generation stopped for unknown reason');
    }

    if (!response.candidates?.[0]?.content?.parts) {
      throw new Error('No response content');
    }

    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.data) {
        return `data:image/png;base64, ${part.inlineData.data}`;
      }
    }

    throw new Error('No image data in response content');
  }

  private async generateWithImagen(userPrompt: string): Promise<string | null> {
    // Imagen uses a different API method: generateImages
    // The @google/genai SDK provides this via ai.models.generateImages
    const response = await this.ai.models.generateImages({
      model: this.model,
      prompt: this.systemPrompt + userPrompt,
      config: {
        numberOfImages: 1,
        aspectRatio: '1:1',
        personGeneration: 'ALLOW_ALL' as any,
      },
    });

    // Imagen response format: { generatedImages: [{ image: { imageBytes: base64 } }] }
    if (response.generatedImages && response.generatedImages.length > 0) {
      const img = response.generatedImages[0].image;
      if (img && img.imageBytes) {
        return `data:image/png;base64, ${img.imageBytes}`;
      }
    }

    throw new Error('No image generated by Imagen');
  }

  /**
   * Enqueues a batch generation job.
   * Note: Batch generation only supports Gemini models, not Imagen.
   * @param prompts List of text prompts.
   * @param name Optional display name for the batch job.
   * @returns The created batch job object.
   */
  async enqueue(prompts: string[], name?: string): Promise<any> {
    if (this.modelType === 'imagen') {
      throw new Error('Batch generation is not supported for Imagen models');
    }

    const lines = prompts.map((prompt) => {
      return JSON.stringify({
        request: {
          contents: [
            {
              role: 'user',
              parts: [{ text: this.systemPrompt + prompt }],
            },
          ],
          generationConfig: {
            responseModalities: ['IMAGE'],
          },
        },
      });
    });

    const jsonlContent = lines.join('\n');
    const file = new File([jsonlContent], 'batch.jsonl', {
      type: 'application/json',
    });

    const uploadResult = await this.ai.files.upload({
      file,
      config: { mimeType: 'application/json' },
    });

    if (!uploadResult.name) {
      throw new Error('Failed to upload batch file');
    }

    return await this.ai.batches.create({
      model: this.model,
      src: uploadResult.name,
      config: name ? { displayName: name } : undefined,
    });
  }

  /**
   * Queries the status of a batch job.
   * @param name The resource name of the batch job (e.g. "jobs/...").
   * @returns The latest batch job object.
   */
  async query(name: string): Promise<any> {
    return await this.ai.batches.get({ name });
  }

  /**
   * Retrieves and parses the results of a completed batch job.
   * @param outputFileName The resource name of the output file (e.g. "files/...").
   * @returns Array of base64 image strings.
   */
  async get(outputFileName: string): Promise<string[]> {
    // Download using fetch because ai.files.download is not supported in browser
    const response = await fetch(
      `https://generativelanguage.googleapis.com/download/v1beta/${outputFileName}:download?key=${this.apiKey}&alt=media`,
    );

    if (!response.ok) {
      throw new Error(`Failed to download results: ${response.statusText}`);
    }

    const fileContent = await response.text();
    const results: string[] = [];

    for (const line of fileContent.split('\n')) {
      if (line) {
        try {
          const parsedResponse = JSON.parse(line);
          if (parsedResponse.response) {
            for (const part of parsedResponse.response.candidates[0].content
              .parts) {
              if (part.inlineData && part.inlineData.data) {
                results.push(`data:image/png;base64, ${part.inlineData.data}`);
              }
            }
          } else if (parsedResponse.error) {
            // Log or handle individual item error
            console.error(
              `Batch item error: ${JSON.stringify(parsedResponse.error)}`,
            );
          }
        } catch (e) {
          console.error('Failed to parse result line', e);
        }
      }
    }

    return results;
  }
}
